{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f67dab",
   "metadata": {},
   "source": [
    "# Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643554b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data = \"../.data/AdVitam/Exp4/Preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bfbdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = pd.read_csv(os.path.join(root_data, \"Physio/periods/features_segm_5.csv\"))\n",
    "takeover = pd.read_csv(os.path.join(root_data, \"Physio/takeover_interval/features_tor_10s_30s_with_driving_features.csv\"))\n",
    "questions = pd.read_csv(os.path.join(root_data, \"Questionnaire/Exp4_Database.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b814a",
   "metadata": {},
   "source": [
    "# EDA - Periods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182139a4",
   "metadata": {},
   "source": [
    "\n",
    "## Single file EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "period.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388b0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "takeover.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf28e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "period[period['subject_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "period[['subject_id', 'label_sleep']].drop_duplicates().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e1ab47",
   "metadata": {},
   "source": [
    "## Dataset EDA \n",
    "\n",
    "The data doesn't seem to be consistent as there are differing % of missing values across different periods / segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e967d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_datasets_missing_data():\n",
    "   import glob\n",
    "   import os\n",
    "   \n",
    "   pattern = os.path.join(root_data, \"Physio/periods/features_segm_*.csv\")\n",
    "   csv_files = glob.glob(pattern)\n",
    "   results = []\n",
    "   \n",
    "   for file_path in csv_files:\n",
    "       df = pd.read_csv(file_path)\n",
    "       missing_info = pd.DataFrame({\n",
    "           'Missing Count': df.isnull().sum(),\n",
    "           'Missing Percentage': (df.isnull().sum() / len(df)) * 100\n",
    "       })\n",
    "       \n",
    "       missing_only = missing_info[missing_info['Missing Count'] > 0]\n",
    "       \n",
    "       results.append({\n",
    "           'File': os.path.basename(file_path),\n",
    "           'Total_Columns': len(df.columns),\n",
    "           'Missing_Columns': len(missing_only),\n",
    "       })\n",
    "   \n",
    "   results_df = pd.DataFrame(results)\n",
    "   return results_df\n",
    "\n",
    "analyze_all_datasets_missing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09408e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_datasets_missing_data():\n",
    "   \n",
    "   pattern = os.path.join(root_data, \"Physio/periods/features_segm_*.csv\")\n",
    "   csv_files = glob.glob(pattern)\n",
    "   \n",
    "   # Dictionary to store missing percentages for each file\n",
    "   all_missing_percentages = {}\n",
    "   \n",
    "   for file_path in csv_files:\n",
    "       df = pd.read_csv(file_path)\n",
    "       missing_pct = (df.isnull().sum() / len(df)) * 100\n",
    "       \n",
    "       # Extract segm_n from filename\n",
    "       filename = os.path.basename(file_path)\n",
    "       segm_name = filename.replace('features_', '').replace('.csv', '')\n",
    "       all_missing_percentages[segm_name] = missing_pct\n",
    "   \n",
    "   # Create comparison dataframe\n",
    "   comparison_df = pd.DataFrame(all_missing_percentages)\n",
    "   \n",
    "   # Only keep rows (features) that have missing data in at least one file\n",
    "   comparison_df = comparison_df[(comparison_df > 0).any(axis=1)]\n",
    "   \n",
    "   # Fill NaN with 0 (meaning no missing data for that feature in that file)\n",
    "   comparison_df = comparison_df.fillna(0)\n",
    "   \n",
    "   # Sort columns by numeric order\n",
    "   cols = [col for col in comparison_df.columns if col.startswith('segm_')]\n",
    "   cols_sorted = sorted(cols, key=lambda x: int(x.split('_')[1]))\n",
    "   comparison_df = comparison_df[cols_sorted]\n",
    "   \n",
    "   # Add average missing percentage column\n",
    "   comparison_df['Average_Missing'] = comparison_df.mean(axis=1)\n",
    "   \n",
    "   # Sort by average missing percentage (descending)\n",
    "   comparison_df = comparison_df.sort_values('Average_Missing', ascending=False)\n",
    "   \n",
    "   return comparison_df\n",
    "\n",
    "analyze_all_datasets_missing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c195775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92669bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_info = pd.DataFrame({\n",
    "    'Missing Count': questions.isnull().sum(),\n",
    "    'Missing Percentage': (questions.isnull().sum() / len(questions)) * 100\n",
    "})\n",
    "print(missing_info[missing_info['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[questions['time_sleep_raw'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d1062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc99fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sleep_deprivation_analysis(period_data):\n",
    "   \"\"\"\n",
    "   Create physiological changes visualization over segment_id, separated by urban/rural periods\n",
    "   \"\"\"\n",
    "   \n",
    "   # Claude generated\n",
    "   \n",
    "   # Key features selected based on sleep deprivation research findings\n",
    "   key_features = [\n",
    "       'ECG_Rate_Mean_Dr',      # Heart rate - fundamental autonomic response, increases with fatigue/stress\n",
    "                                # Research: Direct indicator of sympathetic activation during sleep deprivation\n",
    "       \n",
    "       'EDA_filtered_mean_Dr',  # EDA mean - sympathetic nervous system activation marker\n",
    "                                # Research: Greco et al. (2017) found EDA higher frequencies most sensitive to sleep deprivation\n",
    "                                # Reduced SNS activation occurs with physical fatigue from sleep loss\n",
    "       \n",
    "       'HRV_RMSSD_Dr',         # Root Mean Square of Successive Differences - parasympathetic tone indicator\n",
    "                               # Research: RMSSD reflects recovery capacity and vagal tone\n",
    "                               # Decreases significantly with sleep deprivation, indicating reduced autonomic recovery\n",
    "       \n",
    "       'HRV_LF_Dr',            # Low Frequency HRV (0.04-0.15 Hz) - sympathetic activity marker\n",
    "                               # Research: LF power changes reflect sympathetic nervous system modulation\n",
    "                               # Important for detecting autonomic dysfunction during fatigue\n",
    "       \n",
    "       'HRV_HF_Dr',            # High Frequency HRV (0.15-0.4 Hz) - parasympathetic activity marker  \n",
    "                               # Research: HF power directly reflects vagal tone and respiratory sinus arrhythmia\n",
    "                               # Decreases with sleep deprivation indicating autonomic imbalance\n",
    "       \n",
    "       'SCR_Peaks_freq_Dr'     # Skin Conductance Response peak frequency - arousal/alertness indicator\n",
    "                               # Research: SCR frequency correlates with cognitive arousal and attention\n",
    "                               # Decreases with sleepiness, making it ideal for driver alertness monitoring\n",
    "   ]\n",
    "   \n",
    "   # Feature selection rationale:\n",
    "   # 1. ECG_Rate_Mean_Dr: Most fundamental and reliable autonomic measure, changes predictably with fatigue\n",
    "   # 2. EDA_filtered_mean_Dr: Research shows EDA is most sensitive to sleep deprivation effects on SNS\n",
    "   # 3. HRV_RMSSD_Dr: Gold standard for parasympathetic assessment, critical for recovery capacity\n",
    "   # 4. HRV_LF_Dr & HRV_HF_Dr: Complementary autonomic measures (sympathetic vs parasympathetic balance)\n",
    "   # 5. SCR_Peaks_freq_Dr: Direct measure of moment-to-moment alertness, crucial for driving safety\n",
    "   #\n",
    "   # These 6 features provide comprehensive autonomic nervous system assessment:\n",
    "   # - Basic cardiac response (heart rate)\n",
    "   # - Sympathetic activation (EDA, LF HRV)  \n",
    "   # - Parasympathetic function (RMSSD, HF HRV)\n",
    "   # - Alertness/arousal (SCR frequency)\n",
    "   \n",
    "   # Assuming period column contains 'urban' and 'rural' values\n",
    "   urban_data = period_data[period_data['period'].str.contains('urban', case=False, na=False)]\n",
    "   rural_data = period_data[period_data['period'].str.contains('rural', case=False, na=False)]\n",
    "   \n",
    "   # Create the plot - 2 rows (urban/rural) x 3 columns (features)\n",
    "   fig, axes = plt.subplots(4, 3, figsize=(18, 16))\n",
    "   \n",
    "   feature_labels = [\n",
    "       'Heart Rate (BPM)',\n",
    "       'EDA Mean (ŒºS)', \n",
    "       'HRV RMSSD (ms)',\n",
    "       'HRV LF Power',\n",
    "       'HRV HF Power',\n",
    "       'SCR Peak Frequency'\n",
    "   ]\n",
    "   \n",
    "   colors = ['#2E86AB', '#A23B72']  # Blue for normal, Red for sleep deprived\n",
    "   \n",
    "   # Plot urban data (first 2 rows)\n",
    "   for idx in range(6):\n",
    "       row = idx // 3\n",
    "       col = idx % 3\n",
    "       ax = axes[row, col]\n",
    "       \n",
    "       feature = key_features[idx]\n",
    "       label = feature_labels[idx]\n",
    "       \n",
    "       if feature not in urban_data.columns:\n",
    "           continue\n",
    "           \n",
    "       # Group by sleep condition and segment_id for urban data\n",
    "       sleep_grouped = urban_data.groupby(['label_sleep', 'segment_id'])[feature].agg(['mean', 'std', 'count']).reset_index()\n",
    "       \n",
    "       # Separate data for each sleep condition\n",
    "       normal_sleep = sleep_grouped[sleep_grouped['label_sleep'] == 0]\n",
    "       sleep_deprived = sleep_grouped[sleep_grouped['label_sleep'] == 1]\n",
    "       \n",
    "       # Plot with error bars\n",
    "       if not normal_sleep.empty:\n",
    "           normal_se = normal_sleep['std'] / np.sqrt(normal_sleep['count'])\n",
    "           ax.errorbar(normal_sleep['segment_id'], normal_sleep['mean'], \n",
    "                      yerr=normal_se, color=colors[0], linewidth=3, \n",
    "                      marker='o', markersize=8, capsize=5,\n",
    "                      label='Normal Sleep', alpha=0.8)\n",
    "       \n",
    "       if not sleep_deprived.empty:\n",
    "           deprived_se = sleep_deprived['std'] / np.sqrt(sleep_deprived['count'])\n",
    "           ax.errorbar(sleep_deprived['segment_id'], sleep_deprived['mean'], \n",
    "                      yerr=deprived_se, color=colors[1], linewidth=3,\n",
    "                      marker='s', markersize=8, capsize=5,\n",
    "                      label='Sleep Deprived', alpha=0.8)\n",
    "       \n",
    "       ax.set_xlabel('Segment ID', fontsize=12, fontweight='bold')\n",
    "       ax.set_ylabel(label, fontsize=12, fontweight='bold')\n",
    "       ax.set_title(f'Urban: {label}', fontsize=14, fontweight='bold')\n",
    "       ax.grid(True, alpha=0.3)\n",
    "       ax.legend(fontsize=10)\n",
    "   \n",
    "   # Plot rural data (last 2 rows)\n",
    "   for idx in range(6):\n",
    "       row = (idx // 3) + 2  # Start from row 2\n",
    "       col = idx % 3\n",
    "       ax = axes[row, col]\n",
    "       \n",
    "       feature = key_features[idx]\n",
    "       label = feature_labels[idx]\n",
    "       \n",
    "       if feature not in rural_data.columns:\n",
    "           continue\n",
    "           \n",
    "       # Group by sleep condition and segment_id for rural data\n",
    "       sleep_grouped = rural_data.groupby(['label_sleep', 'segment_id'])[feature].agg(['mean', 'std', 'count']).reset_index()\n",
    "       \n",
    "       # Separate data for each sleep condition\n",
    "       normal_sleep = sleep_grouped[sleep_grouped['label_sleep'] == 0]\n",
    "       sleep_deprived = sleep_grouped[sleep_grouped['label_sleep'] == 1]\n",
    "       \n",
    "       # Plot with error bars\n",
    "       if not normal_sleep.empty:\n",
    "           normal_se = normal_sleep['std'] / np.sqrt(normal_sleep['count'])\n",
    "           ax.errorbar(normal_sleep['segment_id'], normal_sleep['mean'], \n",
    "                      yerr=normal_se, color=colors[0], linewidth=3, \n",
    "                      marker='o', markersize=8, capsize=5,\n",
    "                      label='Normal Sleep', alpha=0.8)\n",
    "       \n",
    "       if not sleep_deprived.empty:\n",
    "           deprived_se = sleep_deprived['std'] / np.sqrt(sleep_deprived['count'])\n",
    "           ax.errorbar(sleep_deprived['segment_id'], sleep_deprived['mean'], \n",
    "                      yerr=deprived_se, color=colors[1], linewidth=3,\n",
    "                      marker='s', markersize=8, capsize=5,\n",
    "                      label='Sleep Deprived', alpha=0.8)\n",
    "       \n",
    "       ax.set_xlabel('Segment ID', fontsize=12, fontweight='bold')\n",
    "       ax.set_ylabel(label, fontsize=12, fontweight='bold')\n",
    "       ax.set_title(f'Rural: {label}', fontsize=14, fontweight='bold')\n",
    "       ax.grid(True, alpha=0.3)\n",
    "       ax.legend(fontsize=10)\n",
    "   \n",
    "   plt.tight_layout()\n",
    "   \n",
    "   fig.suptitle('Physiological Changes Over Segments: Urban vs Rural Driving\\n' +\n",
    "               'Sleep Deprived vs Normal Sleep Conditions', \n",
    "               fontsize=16, fontweight='bold', y=0.98)\n",
    "   \n",
    "   return fig\n",
    "\n",
    "fig = create_sleep_deprivation_analysis(period)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6bb422",
   "metadata": {},
   "source": [
    "# Visualization (Correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d8aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('../.data/AdVitam/Exp4/Preprocessed/Physio/periods/features_segm_10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93570d7a",
   "metadata": {},
   "source": [
    "In the classification paper, to me this is odd. The top 10 features here include baseline values. However, the baseline values across periods are the same (because its the same subject). Therefore, it essentially acts as a subject id? \n",
    "\n",
    "See how below there's no duplicate subject id (total rows = 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf479f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['subject_id', 'SCR_Peaks_Amplitude_Mean_Bl', 'EDA_tonic_min_Bl', 'SCR_Peaks_freq_Bl']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18375719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 features from Meteier et al. paper (Table 8)\n",
    "# These are the most predictive features for sleep deprivation detection\n",
    "top_10_features = [\n",
    "    'SCR_Peaks_Amplitude_Mean_Bl',  # 1. Mean Amplitude of SCRs\n",
    "    'EDA_tonic_min_Bl',             # 2. Minimum tonic EDA level (Bl)\n",
    "    'EDA_filtered_std_Bl',          # 3. SD of raw EDA level (Bl)\n",
    "    'SCR_Peaks_N_Bl',               # 4. Number of SCRs per minute (Bl)\n",
    "    'EDA_tonic_max_Bl',             # 5. Maximum tonic EDA level (Bl)\n",
    "    'SCR_Peaks_freq_Bl',            # 6. Number of SCRs per minute\n",
    "    'EDA_filtered_min_Bl',          # 7. Minimum raw EDA level\n",
    "    'SCR_Peaks_Amplitude_Mean_Dr',  # 8. Mean Amplitude of SCRs (Dr)\n",
    "    'EDA_filtered_max_Bl',          # 9. Maximum raw EDA level (Bl)\n",
    "    'EDA_filtered_std_Dr'           # 10. SD of raw EDA level (Bl)\n",
    "]\n",
    "\n",
    "sns.heatmap(df[['label_sleep'] + top_10_features].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779fce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all feature columns (exclude metadata)\n",
    "metadata_cols = ['subject_id', 'label_sleep', 'label_first_scenario', 'label_time_exp', \n",
    "                 'period', 'segment_id', 'time_start', 'time_end']\n",
    "feature_cols = [col for col in df.columns if col not in metadata_cols]\n",
    "\n",
    "# Calculate correlation of all features with sleep deprivation\n",
    "correlations = df[feature_cols + ['label_sleep']].corr()['label_sleep'].drop('label_sleep')\n",
    "top_10_correlated = correlations.abs().sort_values(ascending=False).head(10)\n",
    "\n",
    "print(f\"Top 10 most correlated features with sleep deprivation:\")\n",
    "for i, (feat, corr) in enumerate(top_10_correlated.items(), 1):\n",
    "    print(f\"{i:2d}. {feat}: {correlations[feat]:.3f}\")\n",
    "\n",
    "# Heatmap of top 10 correlated features\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df[['label_sleep'] + top_10_correlated.index.tolist()].corr(), \n",
    "            annot=True, cmap='RdBu_r', center=0, fmt='.3f')\n",
    "plt.title('Top 10 Most Correlated Features with Sleep Deprivation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018c220",
   "metadata": {},
   "source": [
    "# Test a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf55429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Features and target\n",
    "X = df[feature_cols].fillna(0)  # Simple fillna for missing values\n",
    "X = X.replace([np.inf, -np.inf], 0)  # Replace inf values\n",
    "y = df['label_sleep']\n",
    "groups = df['subject_id']  # For proper splitting\n",
    "\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Samples: {len(y)}\")\n",
    "print(f\"Sleep distribution: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# Split by participants (proper way)\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "train_idx, test_idx = next(splitter.split(X, y, groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "print(f\"\\nTrain: {len(X_train)} samples, {len(X_train.groupby(groups.iloc[train_idx]).size())} participants\")\n",
    "print(f\"Test: {len(X_test)} samples, {len(X_test.groupby(groups.iloc[test_idx]).size())} participants\")\n",
    "\n",
    "# Train XGBoost\n",
    "model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nTest Accuracy: {accuracy:.3f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "print(f\"\\nTop 10 Feature Importances:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b7038b",
   "metadata": {},
   "source": [
    "# Test for similarity amongst baseline for the between-subject groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf503c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Check baseline differences between sleep-deprived and well-rested groups\n",
    "baseline_features = [f for f in df.columns if f.endswith('_Bl')]\n",
    "\n",
    "for feature in baseline_features:\n",
    "    sleep_depr = df[df['label_sleep'] == 1][feature]\n",
    "    well_rest = df[df['label_sleep'] == 0][feature]\n",
    "    \n",
    "    # T-test\n",
    "    t_stat, p_value = stats.ttest_ind(sleep_depr, well_rest)\n",
    "    \n",
    "    print(f\"{feature}:\")\n",
    "    print(f\"  Sleep Deprived: Œº={sleep_depr.mean():.3f}, œÉ={sleep_depr.std():.3f}\")\n",
    "    print(f\"  Well Rested:    Œº={well_rest.mean():.3f}, œÉ={well_rest.std():.3f}\")\n",
    "    print(f\"  T-test p-value: {p_value:.3f}\")\n",
    "    print(f\"  Significant:    {'YES' if p_value < 0.05 else 'NO'}\")\n",
    "    print()\n",
    "\n",
    "# Summary\n",
    "significant_count = sum([stats.ttest_ind(df[df['label_sleep'] == 1][f], \n",
    "                                        df[df['label_sleep'] == 0][f])[1] < 0.05 \n",
    "                        for f in baseline_features])\n",
    "\n",
    "print(f\"SUMMARY: {significant_count}/{len(baseline_features)} baseline features differ significantly\")\n",
    "print(f\"Percentage: {significant_count/len(baseline_features)*100:.1f}%\")\n",
    "\n",
    "if significant_count/len(baseline_features) > 0.5:\n",
    "    print(\"üö® MAJOR PROBLEM: Most baselines differ - model likely learning individual differences\")\n",
    "elif significant_count/len(baseline_features) > 0.3:\n",
    "    print(\"‚ö†Ô∏è PROBLEM: Many baselines differ - results questionable\")\n",
    "else:\n",
    "    print(\"‚úÖ Baselines look reasonable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c79e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
