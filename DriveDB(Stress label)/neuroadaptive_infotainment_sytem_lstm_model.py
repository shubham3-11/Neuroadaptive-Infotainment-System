# -*- coding: utf-8 -*-
"""Neuroadaptive Infotainment Sytem LSTM Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JXajDraTn99BwAL0cakkVf0Vo1gwibfV

# Driver Stress Classification with LSTM (Neuroadaptive Infotainment System)
In this notebook, we build an end-to-end pipeline for binary stress classification using drivers' physiological signals. We use the DriveDB dataset from Healey & Picard's study
physionet.org
, which contains multi-channel recordings (ECG, EMG, GSR from hand and foot, respiration, heart rate) sampled at **256 Hz.** Some recordings include an additional marker channel indicating externally observed stress events
physionet.org
.

 We will segment the signals into fixed-length time windows and assign a stress label to each window based on the frequency of marker events in that window – specifically, windows with marker activity above the 75th percentile are labeled as "High Stress" (1) and the rest as "Low/No Stress" (0).

Using these labeled time-series windows, we train a Long Short-Term Memory (LSTM) neural network to classify stress. The notebook is organized as follows:

**1.Load Data** – Load the physiological signal data for each driving session.

**2.Labeling and Segmentation** – Segment data into fixed-duration windows and label each with stress vs. non-stress using the marker channel (75th percentile threshold).

**3.Preprocessing** – Prepare input features (retain raw time-series, no feature flattening) and normalize the signals for training.

**4.Train/Validation Split** – Split the dataset into training and validation sets.

**5.Model Definition (LSTM)** – Define a minimal LSTM-based classifier model using PyTorch.

**6.Training** – Train the model on the training set and monitor loss and accuracy on both train and validation sets.

**7.Evaluation** – Evaluate the trained model on the validation set and report accuracy, precision, recall, and F1-score.


Refinement needed:-
2)Visulization as previousy done
3)Split is not ideal for time series
4)Summary of the architecture
"""

#  Install required packages
!pip install wfdb numpy pandas scikit-learn torch
!pip install torchsummary
!pip install torchinfo
# Import libraries
import os
import numpy as np
import pandas as pd
import wfdb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
from torchsummary import summary

# Set random seed for reproducibility
np.random.seed(42)
torch.manual_seed(42)

"""# 1. Load Data
We use the WFDB library to read each driver's recording from the dataset. Each record is loaded and we pad any missing channels with zeros so that all sessions have a uniform set of 7 channels (ECG, EMG, foot GSR, hand GSR, HR, RESP, marker). The DriveDB data files (*.hea and *.dat) are present in data_dir
"""

# ------------------ Save Kaggle API Credentials ------------------
# This is required to use kagglehub and download datasets
import kagglehub
os.makedirs(os.path.expanduser("~/.kaggle"), exist_ok=True)
with open(os.path.expanduser("~/.kaggle/kaggle.json"), "w+") as f:
    f.write('{"username":"","key":""}') #Please enter your crredentials

# ------------------ Download Dataset from Kaggle ------------------
# This will download the latest version to a local path
path = kagglehub.dataset_download("bjoernjostein/stress-recognition-in-automobile-drivers")
print("Path to dataset files:", path)
config = {
    "data_dir": path}

import os

# Top-level path returned by kagglehub
path = kagglehub.dataset_download("bjoernjostein/stress-recognition-in-automobile-drivers")
print("Top-level dataset path:", path)

# Check contents
print("Files/folders:", os.listdir(path))

# Check if it contains a nested folder like 'physionet.org'
nested_dirs = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]
if "physionet.org" in nested_dirs:
    nested_path = os.path.join(path, "physionet.org")
    print("Detected nested dataset folder:", nested_path)
    config["data_dir"] = nested_path
else:
    config["data_dir"] = path

config["data_dir"] = os.path.join(
    path, "physionet.org", "files", "drivedb", "1.0.0"
)

data_dir = config["data_dir"]
record_files = [f for f in os.listdir(data_dir) if f.endswith(".hea")]
print("HEA files:", record_files)

# Define the data directory


# List all record files in the directory (PhysioNet records have .hea headers)
record_files = [f for f in os.listdir(data_dir) if f.endswith(".hea")]
record_files.sort()
print(f"Found {len(record_files)} record files in {data_dir}")

# Desired channel order for all records
desired_channels = ["ECG", "EMG", "foot GSR", "hand GSR", "HR", "RESP", "marker"]

# Load each record and pad channels to have a uniform 7-channel array
all_records = []
for filename in record_files:
    record_name = filename[:-4]  # remove .hea extension to get base name
    # Read the record using WFDB (this will read the .hea and corresponding .dat file)
    record = wfdb.rdrecord(os.path.join(data_dir, record_name))
    signals = record.p_signal        # numpy array of shape (N_samples, n_channels)
    channels = record.sig_name      # list of channel names in this record
    # Initialize array for this record with 7 columns (all channels), fill with zeros
    sig_array = np.zeros((signals.shape[0], len(desired_channels)))
    for i, ch in enumerate(desired_channels):
        if ch in channels:
            idx = channels.index(ch)
            sig_array[:, i] = signals[:, idx]
    all_records.append(sig_array)
print("Loaded all sessions into memory. Total sessions:", len(all_records))

"""# 2. Labeling and Segmentation
Now we segment each session into fixed-length windows and assign stress labels. Here we use **10-second windows** (with sampling rate 256 Hz, each window has **2560 samples**). For each window, we compute the average value of the marker channel, then determine the 75th-percentile of these averages across all window). Windows with marker mean above this threshold are labeled as High Stress (1), and the rest as Low/No Stress (0).
"""

# Segment signals into fixed-length windows and compute marker means
fs = 256  # sampling frequency (Hz)
window_size_sec = 10
window_len = fs * window_size_sec  # samples per window (2560 for 10s)

X_windows = []    # list to collect window segments
marker_means = [] # list to collect mean marker value for each window

for rec_data in all_records:
    n_samples = rec_data.shape[0]
    # Segment the record into consecutive windows (no overlap)
    for start in range(0, n_samples - window_len + 1, window_len):
        window = rec_data[start : start + window_len, :]  # shape: (window_len, 7)
        X_windows.append(window)
        # Compute average of marker channel (last column) in this window
        mean_marker = np.mean(window[:, -1])
        marker_means.append(mean_marker)

# Determine threshold for "high stress" as 75th percentile of marker average】
threshold = np.percentile(marker_means, 75)
print(f"75th percentile of marker_mean = {threshold:.4f}")

# Label windows: 1 if marker_mean > threshold (High Stress), else 0
y_labels = [1 if m > threshold else 0 for m in marker_means]

# Convert to numpy arrays for convenience
X_windows = np.array(X_windows)  # shape: (num_windows, window_len, 7)
y_labels = np.array(y_labels)
print(f"Total windows segmented: {len(y_labels)}")
print(f"High-Stress windows: {sum(y_labels)}, Low-Stress windows: {len(y_labels) - sum(y_labels)}")

"""# 3. Preprocessing
Next, we prepare the data for model training. We drop the marker channel from the input features (since it's not a sensor signal used for prediction) and perform z-score normalization on each of the remaining channels across all windows. This ensures each feature has mean 0 and unit variance, which helps the model training converge.
"""

# Drop the marker channel from inputs (we'll use only the sensor features for modeling)
X_features = X_windows[:, :, :6]   # shape: (num_windows, window_len, 6)

# Normalize features across all windows (z-score normalization per channel)
channel_means = X_features.mean(axis=(0, 1))
channel_stds = X_features.std(axis=(0, 1))
channel_stds[channel_stds == 0] = 1.0  # avoid division by zero if any constant channel

X_features = (X_features - channel_means) / channel_stds

print("Input feature shape (num_windows, seq_len, num_channels):", X_features.shape)

"""# 4. Train/Validation Split
Now we split the data into training and validation sets for model development. We'll use 80% of the windows for training and 20% for validation, using stratified sampling to maintain class balance. (In practice, one could split by driver to ensure no individual appears in both training and validation sets, to avoid subject-wise bias. Here we perform a random split for simplicity.) After splitting, we convert the datasets into PyTorch DataLoader objects for convenient batch processing.
"""

# Split the dataset into training and validation sets (80% train, 20% val)
# X_train, X_val, y_train, y_val = train_test_split(
#     X_features, y_labels, test_size=0.2, stratify=y_labels, random_state=42
# )
# print(f"Training windows: {len(y_train)}, Validation windows: {len(y_val)}")

# Time series split - preserve temporal order
split_ratio = 0.8
split_index = int(len(X_features) * split_ratio)

X_train, X_val = X_features[:split_index], X_features[split_index:]
y_train, y_val = y_labels[:split_index], y_labels[split_index:]

print(f"Training windows: {len(y_train)}, Validation windows: {len(y_val)}")


# Convert splits to PyTorch tensors
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.long)
X_val_tensor   = torch.tensor(X_val, dtype=torch.float32)
y_val_tensor   = torch.tensor(y_val, dtype=torch.long)

# Create DataLoader for batch training
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
val_dataset   = TensorDataset(X_val_tensor, y_val_tensor)
train_loader  = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader    = DataLoader(val_dataset, batch_size=32, shuffle=False)

# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import StandardScaler
# import torch
# import numpy as np

# # 1. Unique subject IDs
# subjects = np.array(list(set(all_subjects)))

# # 2. Compute a majority label per subject
# subject_labels = np.array([
#     1 if np.mean(y[np.array(all_subjects) == subj]) > 0.5 else 0
#     for subj in subjects
# ])

# # 3. Stratified subject-wise split
# train_subjects, val_subjects = train_test_split(
#     subjects,
#     test_size=config["test_size"],
#     random_state=config["seed"],
#     stratify=subject_labels
# )

# # 4. Get indices for train and val samples
# train_idx = [i for i, subj in enumerate(all_subjects) if subj in train_subjects]
# val_idx   = [i for i, subj in enumerate(all_subjects) if subj in val_subjects]

# # 5. Split data
# X_train, y_train = X[train_idx], y[train_idx]
# X_val, y_val     = X[val_idx], y[val_idx]

# print(f"Train subjects: {len(train_subjects)}, Val subjects: {len(val_subjects)}")
# print(f"Train samples: {X_train.shape[0]}, Val samples: {X_val.shape[0]}")

# # 6. Normalize across training set (for CNN/LSTM time-series input)
# #    Reshape to 2D: (num_samples * window_len, num_channels)
# train_reshaped = X_train.reshape(-1, X_train.shape[-1])
# mean_vals = train_reshaped.mean(axis=0)
# std_vals  = train_reshaped.std(axis=0)
# std_vals[std_vals == 0] = 1.0  # avoid division by zero

# X_train = (X_train - mean_vals) / std_vals
# X_val   = (X_val   - mean_vals) / std_vals

# # 7. Convert to torch tensors for PyTorch
# X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
# y_train_tensor = torch.tensor(y_train, dtype=torch.long)
# X_val_tensor   = torch.tensor(X_val, dtype=torch.float32)
# y_val_tensor   = torch.tensor(y_val, dtype=torch.long)

# print("Final train tensor shape:", X_train_tensor.shape)
# print("Final val tensor shape:", X_val_tensor.shape)

"""# 5. Model Definition (LSTM)
Next, we define our neural network model. We use a simple LSTM-based architecture: an LSTM layer (with hidden size 64 and 2 layers, using dropout) followed by a fully-connected layer to produce the two output classes. We set batch_first=True so that each input batch has shape *(batch_size, sequence_length, num_features). The model uses the last hidden state of the LSTM to predict the stress class for each window.
"""

# # Define LSTM-based classification model
# num_features = X_train_tensor.shape[2]  # number of features per time step
# hidden_size = 64
# num_layers = 2
# num_classes = 2

# class LSTMClassifier(nn.Module):
#     def __init__(self, input_size, hidden_size, num_layers, num_classes):
#         super(LSTMClassifier, self).__init__()
#         self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,
#                              num_layers=num_layers, batch_first=True, dropout=0.5)
#         self.fc   = nn.Linear(hidden_size, num_classes)
#     def forward(self, x):
#         # x shape: (batch, seq_len, input_size)
#         _, (h_n, _) = self.lstm(x)       # h_n shape: (num_layers, batch, hidden_size)
#         last_hidden = h_n[-1]           # last layer's hidden state for final time step
#         out = self.fc(last_hidden)      # output shape: (batch, num_classes)
#         return out


# model = LSTMClassifier(input_size=num_features, hidden_size=hidden_size,
#                        num_layers=num_layers, num_classes=num_classes)
# criterion = nn.CrossEntropyLoss()
# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# # Move model to GPU if available
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# model.to(device)
# print("Model initialized. Using device:", device)

# Define LSTM-based classification model
num_features = X_train_tensor.shape[2]
hidden_size = 64
num_layers = 2
num_classes = 2

class LSTMClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes):
        super(LSTMClassifier, self).__init__()
        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,
                             num_layers=num_layers, batch_first=True, dropout=0.5)
        self.dropout = nn.Dropout(0.3)  # Reduced dropout
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        _, (h_n, _) = self.lstm(x)
        last_hidden = h_n[-1]
        out = self.fc(self.dropout(last_hidden))
        return out

model = LSTMClassifier(input_size=num_features, hidden_size=hidden_size,
                       num_layers=num_layers, num_classes=num_classes)

# Compute class weights and scale them slightly
from sklearn.utils.class_weight import compute_class_weight
import numpy as np

raw_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
scaled_weights = raw_weights * 0.5  # Scale down impact
class_weights = torch.tensor(scaled_weights, dtype=torch.float).to(device)
print("Scaled Class weights:", class_weights)

# Weighted loss
criterion = nn.CrossEntropyLoss(weight=class_weights)

# Optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# Device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("Model initialized. Using device:", device)

print(model)

"""# 6. Training
We train the LSTM model on the training set for a number of epochs. In each epoch, we iterate over batches of training data, compute the loss, and update the model weights. We also evaluate on the validation set each epoch to monitor performance. Below, we print the training and validation loss and accuracy for each epoch:
"""

# 1. Install & import
!pip install wandb -q
import wandb
from tqdm.notebook import tqdm
from IPython.display import clear_output

# 2. Login (run only once, will cache)
wandb.login()

# 3. Init project
wandb.init(project="lstm-driver-stress", config={
    "epochs": 1,
    "batch_size": train_loader.batch_size if hasattr(train_loader, 'batch_size') else 64,
    "learning_rate": 1e-3,
    "hidden_size": 64,
    "num_layers": 2,
    "input_size": 6,
    "sequence_length": 2560
})

# 4. Training loop with wandb + tqdm
num_epochs = wandb.config.epochs

for epoch in range(1, num_epochs + 1):
    model.train()
    total_loss = total_correct = total_samples = 0

    for batch_X, batch_y in tqdm(train_loader, desc=f"Epoch {epoch:02d} [Train]", leave=False):
        batch_X, batch_y = batch_X.to(device), batch_y.to(device)
        optimizer.zero_grad()
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * batch_X.size(0)
        _, pred = torch.max(outputs, 1)
        total_correct += (pred == batch_y).sum().item()
        total_samples += batch_y.size(0)

    avg_train_loss = total_loss / total_samples
    train_acc = total_correct / total_samples

    # Validation
    model.eval()
    val_loss = val_correct = val_samples = 0
    with torch.no_grad():
        for batch_X, batch_y in tqdm(val_loader, desc=f"Epoch {epoch:02d} [Val]", leave=False):
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            val_loss += loss.item() * batch_X.size(0)
            _, pred = torch.max(outputs, 1)
            val_correct += (pred == batch_y).sum().item()
            val_samples += batch_y.size(0)

    avg_val_loss = val_loss / val_samples
    val_acc = val_correct / val_samples

    # Log to Wandb
    wandb.log({
        "epoch": epoch,
        "train_loss": avg_train_loss,
        "train_acc": train_acc,
        "val_loss": avg_val_loss,
        "val_acc": val_acc
    })

    clear_output(wait=True)
    print(f"Epoch {epoch:02d}/{num_epochs} | "
          f"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f} | "
          f"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}")

# 1. Install & import
!pip install wandb -q
import wandb
from tqdm.notebook import tqdm
from IPython.display import clear_output

# 2. Login (run only once, will cache)
wandb.login()

# 3. Init project with 30 epochs
wandb.init(project="lstm-driver-stress", config={
    "epochs": 30,
    "batch_size": train_loader.batch_size if hasattr(train_loader, 'batch_size') else 64,
    "learning_rate": 1e-3,
    "hidden_size": 64,
    "num_layers": 2,
    "input_size": 6,
    "sequence_length": 2560
})

# Set number of epochs from config
num_epochs = wandb.config.epochs

# Early stopping parameters
best_val_loss = float('inf')
patience = 5
counter = 0

# Learning rate scheduler
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)

# Track metrics for epoch summary
epoch_summaries = []

for epoch in range(1, num_epochs + 1):
    model.train()
    total_loss = total_correct = total_samples = 0

    for batch_X, batch_y in tqdm(train_loader, desc=f"Epoch {epoch:02d} [Train]", leave=False):
        batch_X, batch_y = batch_X.to(device), batch_y.to(device)
        optimizer.zero_grad()
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * batch_X.size(0)
        _, pred = torch.max(outputs, 1)
        total_correct += (pred == batch_y).sum().item()
        total_samples += batch_y.size(0)

    avg_train_loss = total_loss / total_samples
    train_acc = total_correct / total_samples

    # Validation
    model.eval()
    val_loss = val_correct = val_samples = 0
    with torch.no_grad():
        for batch_X, batch_y in tqdm(val_loader, desc=f"Epoch {epoch:02d} [Val]", leave=False):
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            val_loss += loss.item() * batch_X.size(0)
            _, pred = torch.max(outputs, 1)
            val_correct += (pred == batch_y).sum().item()
            val_samples += batch_y.size(0)

    avg_val_loss = val_loss / val_samples
    val_acc = val_correct / val_samples

    # Step the learning rate scheduler
    scheduler.step(avg_val_loss)

    # Log to Wandb
    wandb.log({
        "epoch": epoch,
        "train_loss": avg_train_loss,
        "train_acc": train_acc,
        "val_loss": avg_val_loss,
        "val_acc": val_acc,
        "learning_rate": optimizer.param_groups[0]['lr']
    })

    # Save summary for later
    percent_complete = (epoch / num_epochs) * 100
    epoch_summaries.append({
        "epoch": epoch,
        "percent": percent_complete,
        "train_loss": avg_train_loss,
        "train_acc": train_acc,
        "val_loss": avg_val_loss,
        "val_acc": val_acc
    })

    clear_output(wait=True)
    print(f" Epoch {epoch:02d}/{num_epochs} "
          f"({percent_complete:.2f}% complete) | "
          f"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f} | "
          f"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}")

    # Early stopping check
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        counter = 0  # reset counter if validation loss improves
    else:
        counter += 1
        if counter >= patience:
            print(f" Early stopping triggered at epoch {epoch}")
            break

# Final epoch summary
print("\n Epoch Summary:")
for summary in epoch_summaries:
    print(f"Epoch {summary['epoch']:02d} "
          f"({summary['percent']:.2f}%): "
          f"Train Loss={summary['train_loss']:.4f}, "
          f"Train Acc={summary['train_acc']:.4f}, "
          f"Val Loss={summary['val_loss']:.4f}, "
          f"Val Acc={summary['val_acc']:.4f}")

"""# 7. Evaluation
Finally, we evaluate the trained model on the validation set. We compute the overall accuracy as well as the precision, recall, and F1-score for the High Stress class.


"""

# Get predictions on the validation set and compute evaluation metrics
model.eval()
all_preds = []
all_true = []
with torch.no_grad():
    for batch_X, batch_y in val_loader:
        batch_X, batch_y = batch_X.to(device), batch_y.to(device)
        outputs = model(batch_X)
        _, pred = torch.max(outputs, 1)
        all_preds.extend(pred.cpu().numpy())
        all_true.extend(batch_y.cpu().numpy())

all_preds = np.array(all_preds)
all_true = np.array(all_true)
val_accuracy = accuracy_score(all_true, all_preds)
val_precision = precision_score(all_true, all_preds, average='binary')
val_recall = recall_score(all_true, all_preds, average='binary')
val_f1 = f1_score(all_true, all_preds, average='binary')

print(f"Validation Accuracy:  {val_accuracy:.4f}")
print(f"Precision (High-Stress class): {val_precision:.4f}")
print(f"Recall (High-Stress class):    {val_recall:.4f}")
print(f"F1-score (High-Stress class):  {val_f1:.4f}")

from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Full classification report
print("\nClassification Report:")
print(classification_report(all_true, all_preds, digits=4))

# Confusion matrix
cm = confusion_matrix(all_true, all_preds)
print("Confusion Matrix:")
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()